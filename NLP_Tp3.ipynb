{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***************            Pre-processing des données textuelles :*******"
      ],
      "metadata": {
        "id": "Ija3ZTcUHoyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "L98BStOJWe0C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "71jE9Afe_Q8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ee6d40-81f1-4ba2-884d-e9b1432f69b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "data :\n",
            "        fold_id cv_tag  html_id  sent_id  \\\n",
            "0            0  cv000    29590        0   \n",
            "1            0  cv000    29590        1   \n",
            "2            0  cv000    29590        2   \n",
            "3            0  cv000    29590        3   \n",
            "4            0  cv000    29590        4   \n",
            "...        ...    ...      ...      ...   \n",
            "64715        9  cv999    14636       20   \n",
            "64716        9  cv999    14636       21   \n",
            "64717        9  cv999    14636       22   \n",
            "64718        9  cv999    14636       23   \n",
            "64719        9  cv999    14636       24   \n",
            "\n",
            "                                                    text  tag  \n",
            "0      films adapted from comic books have had plenty...  pos  \n",
            "1      for starters , it was created by alan moore ( ...  pos  \n",
            "2      to say moore and campbell thoroughly researche...  pos  \n",
            "3      the book ( or \" graphic novel , \" if you will ...  pos  \n",
            "4      in other words , don't dismiss this film becau...  pos  \n",
            "...                                                  ...  ...  \n",
            "64715  that lack of inspiration can be traced back to...  neg  \n",
            "64716  like too many of the skits on the current inca...  neg  \n",
            "64717  after watching one of the \" roxbury \" skits on...  neg  \n",
            "64718   bump unsuspecting women , and . . . that's all .  neg  \n",
            "64719  after watching _a_night_at_the_roxbury_ , you'...  neg  \n",
            "\n",
            "[64720 rows x 6 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Téléchargement des stopwords et du tokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Chargement des données\n",
        "data = pd.read_csv('movie_review.csv')  # Assurez-vous que le fichier CSV est dans votre répertoire de travail\n",
        "\n",
        "# Prétraitement des données textuelles\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(\"\\ndata :\\n\",data)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "    # Conversion en minuscules et suppression de la ponctuation\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # Suppression des stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "# Appliquer le prétraitement aux données textuelles\n",
        "data['text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"text apres pretraitement  \\n\\n\\n \",data['text'] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he9cSFafVN1Q",
        "outputId": "b6ad9356-0337-4c75-8df1-8f45478d340d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text apres pretraitement  \n",
            "\n",
            "\n",
            "  0        [films, adapted, comic, books, plenty, success...\n",
            "1        [starters, created, alan, moore, eddie, campbe...\n",
            "2        [say, moore, campbell, thoroughly, researched,...\n",
            "3        [book, graphic, novel, pages, long, includes, ...\n",
            "4                           [words, dismiss, film, source]\n",
            "                               ...                        \n",
            "64715    [lack, inspiration, traced, back, insipid, cha...\n",
            "64716    [like, many, skits, current, incarnation, roxb...\n",
            "64717    [watching, one, roxbury, skits, snl, come, awa...\n",
            "64718                          [bump, unsuspecting, women]\n",
            "64719                            [watching, left, exactly]\n",
            "Name: text, Length: 64720, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entraînement du modèle Word2Vec :"
      ],
      "metadata": {
        "id": "zV5IVWdjWvzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement du modèle Word2Vec\n",
        "model = Word2Vec(sentences=data['text'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "print('\\n',model,'\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d6E1VgIVHgz",
        "outputId": "336c74ac-9984-4ffe-eda9-1ec48e87473d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Word2Vec<vocab=37964, vector_size=100, alpha=0.025> \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorisation des reviews de movies :"
      ],
      "metadata": {
        "id": "wYxTfM62W9pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Vectorisation des reviews de movies\n",
        "def vectorize_text(text):\n",
        "    vectors = []\n",
        "    for word in text:\n",
        "        if word in model.wv:\n",
        "            vectors.append(model.wv[word])\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(100)  # Si aucun mot n'est présent dans le modèle, retourne un vecteur de zéros\n",
        "\n",
        "data['Vector'] = data['text'].apply(vectorize_text)\n",
        "print(data['Vector'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7xShKSBVHQ_",
        "outputId": "d3f8d7a5-fdf8-433c-ade3-5e7f742cd588"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [-0.23907714, 0.4008218, 0.4034046, -0.0273781...\n",
            "1        [-0.119350985, 0.3264918, 0.24850626, -0.23630...\n",
            "2        [-0.25180298, 0.38039798, 0.47546935, -0.08274...\n",
            "3        [-0.17594603, 0.4400795, 0.22700986, 0.0237775...\n",
            "4        [-0.21982016, 0.5243043, 0.27953598, 0.2695864...\n",
            "                               ...                        \n",
            "64715    [-0.17481302, 0.37867293, 0.25818866, 0.015624...\n",
            "64716    [-0.20659553, 0.3641056, 0.33478892, 0.0186143...\n",
            "64717    [-0.25206664, 0.44335622, 0.3013041, -0.096540...\n",
            "64718    [-0.13628499, 0.30674675, 0.21505015, -0.15492...\n",
            "64719    [-0.35564566, 0.49446023, 0.49216613, 0.155072...\n",
            "Name: Vector, Length: 64720, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Division des données :"
      ],
      "metadata": {
        "id": "A4tVxx1jXR8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Division des données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.vstack(data['Vector']), data['tag'], test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "PAXlr6OrVHBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construction d&#39;un classificateur :"
      ],
      "metadata": {
        "id": "Uvr9ed6HXY1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construction d'un classificateur (exemple avec Logistic Regression)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "sFBwiAqB_piC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évaluation du modèle :"
      ],
      "metadata": {
        "id": "eqwJu8nsXdtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Évaluation du modèle\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7YKORYcETlC",
        "outputId": "bc9be12f-6a4e-41f1-d9b0-156a887ef63e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5696075401730532\n",
            "Precision: 0.5707504960409738\n",
            "Recall: 0.5696075401730532\n",
            "F1 Score: 0.5653499581270917\n"
          ]
        }
      ]
    }
  ]
}